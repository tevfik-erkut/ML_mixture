# -*- coding: utf-8 -*-
"""mariodone.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1wYwhDV_Qq0PRRKhryU3fLMzKGIahQjKF
"""

pip install gym-super-mario-bros

pip install stable_baselines3

"""## Random Game"""

import gym_super_mario_bros
from nes_py.wrappers import JoypadSpace
import gym
from IPython import display
import matplotlib.pyplot as plt
from stable_baselines3.common.policies import ActorCriticPolicy, ActorCriticCnnPolicy
from stable_baselines3.common.vec_env import DummyVecEnv
from stable_baselines3 import PPO

env = gym_super_mario_bros.make('SuperMarioBros-v0')
env = JoypadSpace(env, [["right"], ["right", "A"]])
env.reset()
for _ in range(100):
    plt.imshow(env.render(mode='rgb_array'))
    display.display(plt.gcf())
    display.clear_output(wait=True)
    
    action = env.action_space.sample()
    env.step(action)

"""## Training a DRL model ( PPO )"""

from stable_baselines3.common.policies import ActorCriticPolicy, ActorCriticCnnPolicy
from stable_baselines3.common.vec_env import DummyVecEnv
from stable_baselines3 import PPO
model = PPO(ActorCriticPolicy, env, verbose=1)
model.learn(total_timesteps=2500)

obs = env.reset()
rewards_list = []
for i in range(5000):
    action, _states = model.predict(obs.copy())
    obs, rewards, dones, info = env.step(action)
    rewards_list.append(rewards)

np.sum(rewards_list)

from stable_baselines3 import A2C

model = A2C("MlpPolicy", env, verbose=1)
model.learn(total_timesteps = 2500)

env = gym_super_mario_bros.make('SuperMarioBros-v0')
env = JoypadSpace(env, [["right"], ["right", "A"]])
obs = env.reset()
rewards_list = []
for i in range(5000):
    action, _states = model.predict(obs.copy())
    obs, rewards, dones, info = env.step(action)
    rewards_list.append(rewards)

np.sum(rewards_list)